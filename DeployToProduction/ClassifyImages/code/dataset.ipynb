{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47c7d5aa-12e1-47a7-adaf-fbed11bcf3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddb6510-fbfb-4ecb-a35c-965c180e1655",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f93a137-b82e-4083-acc2-5664379411b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ITS520Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset of images\n",
    "        data_path: path to images folder. This should contain multiple folders of each class\n",
    "            - images\n",
    "                - cats\n",
    "                    - cat1.jpg\n",
    "                - dogs\n",
    "                    - some-dog.jpg\n",
    "                - ...\n",
    "        root: where the pt file will be / is stored\n",
    "        train: whether to load train or test data\n",
    "        shuffle: whether to shuffle the data\n",
    "            - This should only be used in special cases\n",
    "            - The train and test data should be shuffled together\n",
    "        transform: transform to apply to the data\n",
    "        target_transform: transform to apply to the targets\n",
    "        convert: if the data should be converted from images, or loaded from a pt file\n",
    "        size: size of the images to convert to. This should be the same as the size of the images in the pt file\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_save=\"data.pt\", raw_data=None, train=True, shuffle=False, transform=None, target_transform=None, convert=False, size=32):\n",
    "        self.targets = []\n",
    "        self.labels = []\n",
    "        self.data = []\n",
    "\n",
    "        self.X_train = []\n",
    "        self.X_test = []\n",
    "        self.y_train = []\n",
    "        self.y_test = []\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "\n",
    "        if convert:\n",
    "            self.convert(dataset_save, raw_data, size)\n",
    "        else:\n",
    "            self.load(dataset_save)\n",
    "\n",
    "        seed = int(random.random() * 100) if shuffle else 42\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.targets, test_size=0.2, random_state=seed)\n",
    "\n",
    "        if train:\n",
    "            self.data = self.X_train\n",
    "            self.targets = self.y_train\n",
    "        else:\n",
    "            self.data = self.X_test\n",
    "            self.targets = self.y_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, target = self.data[index], self.targets[index]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return image, target\n",
    "    \n",
    "    def convert(self, dataset_save, raw_data, size):\n",
    "        dataset = []\n",
    "        self.labels = []\n",
    "        targets = []\n",
    "        if not os.path.exists(raw_data):\n",
    "            raise ValueError('Raw image directory does not exist.') \n",
    "        for folder in os.listdir(raw_data):\n",
    "            if folder == \".DS_Store\":\n",
    "                continue\n",
    "\n",
    "            for image in os.listdir(os.path.join(raw_data, folder)):\n",
    "                if folder not in self.labels:\n",
    "                    self.labels.append(folder)\n",
    "                targets.append(self.labels.index(folder))\n",
    "\n",
    "                img_arr = imageio.imread(os.path.join(raw_data, folder, image), pilmode=\"RGB\")\n",
    "                resize = torchvision.transforms.Resize(size)\n",
    "                crop_center = torchvision.transforms.CenterCrop(size)\n",
    "\n",
    "                img = torch.from_numpy(img_arr).permute(2, 0, 1).float()\n",
    "                img = resize(img)\n",
    "                img = crop_center(img)\n",
    "                img /= 255\n",
    "\n",
    "                dataset.append(img)\n",
    "\n",
    "        self.data = torch.stack(dataset)\n",
    "        self.targets = torch.Tensor(targets).type(torch.LongTensor)\n",
    "\n",
    "        torch.save((self.data, self.targets, self.labels), dataset_save)\n",
    "\n",
    "    def load(self, dataset_save):\n",
    "        if not os.path.exists(dataset_save):\n",
    "            raise ValueError('Dataset file does not exist. Try creating the dataset by running with convert=True first.') \n",
    "        self.data, self.targets, self.labels = torch.load(dataset_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "355568ff-5f6e-4f21-90b4-817e3a6d34c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset class loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset class loaded\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
